# DataScience4Finance

## ğŸ“Œ Project Overview
This project aims to **predict future earnings changes using financial data** from publicly traded US companies. Leveraging **machine learning techniques** such as **Random Forest, XGBoost, and Logistic Regression**, the goal is to improve earnings forecasting, a key challenge in financial analysis. The dataset is sourced from **[Kaggle](https://www.kaggle.com/datasets/vadimvanak/step-2)** and contains financial statement data from **SEC filings** from US stock listed companies.

This project was developed as part of the **"Data Science in Finance"** course at the **Technical University of Munich (TUM)**.

---

## ğŸ› ï¸ Installation & Setup

1. Create a new Conda environment:
```bash
conda create --name <your_environment_name> python=3.11
```


2. Activate the environment:
```bash
conda activate <your_environment_name>
```

3. Navigate to the project directory:
```bash
cd path/to/your/project/folder
```

4. Install dependencies from requirements.txt:
```bash
pip install -r requirements.txt
```

## ğŸ“‚ Project Structure

The repository is structured into different folders for exploratory analysis, feature selection, model training, and output storage.

```
ğŸ“¦ DataScience4Finance
 â”£ ğŸ“‚ explanatory_analysis
 â”ƒ â”— ğŸ“œ initial_analysis.ipynb
 â”£ ğŸ“‚ data
 â”ƒ â”— ğŸ“œ (Raw and processed data files + external data) 
 â”£ ğŸ“‚ feature_selection
 â”ƒ â”£ ğŸ“‚ 1_iteration
 â”ƒ â”ƒ â”£ ğŸ“‚ rf
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ rf_feature_importances.csv
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ rf_model.pkl
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ rf_roc_curve.png
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ rf_search_results.csv
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“œ rf_test_predictions.csv
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œ rf_train_results.csv
 â”ƒ â”ƒ â”£ ğŸ“‚ xgb (same output files as for random forest)
 â”ƒ â”ƒ â”— ğŸ“œ mean_feature_importance_1_iteration.png
 â”ƒ â”£ ğŸ“‚ 2_iteration (same structure as previous folder)
 â”ƒ â”£ ğŸ“‚ 3_iteration (same structure as previous folder)
 â”ƒ â”£ ğŸ“œ feature_selection.py
 â”ƒ â”£ ğŸ“œ rf_importance_kept_features.png
 â”ƒ â”— ğŸ“œ xgb_importance_kept_features.png
 â”£ ğŸ“‚ output
 â”ƒ â”£ ğŸ“‚ logistic_regression (same output files as for rf)
 â”ƒ â”£ ğŸ“‚ rf
 â”ƒ â”ƒ â”£ ğŸ“œ rf_best_hyperparameters.json
 â”ƒ â”ƒ â”£ ğŸ“œ rf_feature_importances.csv
 â”ƒ â”ƒ â”£ ğŸ“œ rf_feature_importances.png
 â”ƒ â”ƒ â”£ ğŸ“œ rf_model.pkl
 â”ƒ â”ƒ â”£ ğŸ“œ rf_roc_curve.png
 â”ƒ â”ƒ â”£ ğŸ“œ rf_search_results.csv
 â”ƒ â”ƒ â”£ ğŸ“œ rf_search_results1.png
 â”ƒ â”ƒ â”£ ğŸ“œ rf_test_predictions.csv
 â”ƒ â”ƒ â”£ ğŸ“œ rf_train_predictions.csv
 â”ƒ â”ƒ â”— ğŸ“œ rf_train_results.csv
 â”ƒ â”£ ğŸ“‚ xgb (same output files as for rf)
 â”ƒ â”— ğŸ“‚ xgb_robustness_check (same output files as for rf)
 â”£ ğŸ“‚ training
 â”ƒ â”£ ğŸ“œ final_evaluation.ipynb
 â”ƒ â”£ ğŸ“œ helper_functions.py
 â”ƒ â”£ ğŸ“œ logistic_regression.py
 â”ƒ â”£ ğŸ“œ rf.py
 â”ƒ â”£ ğŸ“œ xgb.py
 â”ƒ â”— ğŸ“œ xgb_robustness_check.py
 â”£ ğŸ“œ .gitignore
 â”£ ğŸ“œ preprocessing.py
 â”£ ğŸ“œ README.md
 â”— ğŸ“œ requirements.txt
 ```

---

## ğŸ“– Repository Explanation

Hereâ€™s what each folder contains:

### ğŸ“‚ `explanatory_analysis/`
- Contains **initial_analysis.ipynb**, which performs **exploratory data analysis (EDA)** on the dataset.
- **First step after retrieving the dataset from Kaggle**:  
  - Run `initial_analysis.ipynb` to **filter the dataset** (e.g., only **10-K reports** are considered).  
  - The **first preprocessed dataset** is then stored in the **`data/` folder** for further use.
  - Run `preprocessing.py` to store cleaned and processed files.


### ğŸ“‚ `data/`
- Stores the **raw and processed datasets**.
- Some large files are **ignored via `.gitignore`**, but datasets can be downloaded from **[Kaggle](https://www.kaggle.com/datasets/vadimvanak/step-2)**. 

### ğŸ“‚ `feature_selection/`
- This folder contains scripts and outputs related to **recursive feature elimination (RFE)**.
- **Subfolders (`1_iteration`, `2_iteration`, `3_iteration`)** store different iterations of feature selection.
- The `rf/` and `xgb/` subfolders contain **feature importance scores** and model-specific outputs.

### ğŸ“‚ `output/`
- Stores **model results**, including:
  - **Hyperparameter settings**
  - **Feature importance rankings**
  - **Model evaluation metrics**
  - **Trained models (`.pkl` files)**

### ğŸ“‚ `training/`
- **Contains scripts for training models:**
  - `logistic_regression.py` â†’ Logistic Regression Model
  - `rf.py` â†’ Random Forest Model
  - `xgb.py` â†’ XGBoost Model
  - `xgb_robustness_check.py` â†’ XGB model without imputed data
  - `final_evaluation.ipynb` â†’ **Final comparison of models**.

### ğŸ“œ Key Files in the Main Directory
- **`.gitignore`** â†’ Prevents large files from being committed.
- **`preprocessing.py`** â†’ Runs data preprocessing and creates a **cleaned dataset**.
- **`requirements.txt`** â†’ Lists all required dependencies for the project.
- **`README.md`** â†’ This documentation file.

## ğŸ“ˆ Model Performance
The models are evaluated based on **Area Under the Curve (AUC)** and other classification metrics.

| Model             | AUC (%)  | Accuracy (%) | Precision (%) | Recall (%) |
|------------------|---------|-------------|--------------|------------|
| **XGBoost**      | **68.10** | **63.27**    | **63.61**     | 53.96      |
| **Random Forest** | 66.22    | 60.45       | 57.17        | 68.46      |
| Logistic Reg.    | 60.31    | 54.42       | 51.35        | **86.58**  |

- **XGBoost** performs best in terms of overall predictive power (AUC: **68.10%**).
- **Random Forest** provides more balanced predictions.
- **Logistic Regression** has the highest recall but struggles with precision.

---

## ğŸ“Œ Key Features Driving Earnings Predictions
The most influential features for predicting earnings changes include:

**ğŸ“Š Financial Metrics:**
- **Earnings per Share (EPS)**
- **Comprehensive Income**
- **Profit/Loss Change**
- **Liabilities Change**

**ğŸ“‰ Macroeconomic Indicators:**
- **U.S. Business Confidence (Lagged & Change)**
- **G20 Business Confidence (Lagged)**

**ğŸ“… Temporal Variables:**
- **Pre-COVID period**
- **Time Elapsed Since 2013**

These features impact model performance and help capture financial trends.


---

## ğŸ“œ License
This project is licensed under the **MIT License**.

---

## ğŸ”— References
This project builds on financial research, particularly:
- Chen et al. (2022) - Machine Learning for Earnings Prediction
- Freeman et al. (1982) - Financial Ratios in Forecasting
- Shroff et al. (2014) - Predicting Corporate Earnings Trends

---

## ğŸ“§ Contact
For any questions or collaborations, feel free to reach out:
- **Authors:** Berivan Kevser Yatki, Dogukan Dogu, Niklas Kothe
- **Affiliation:** TUM - Technical University of Munich